{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/xchen/GANs/WGAN-div-PyTorch-/samples/1204_mnist_matsumoto_1/\"\n",
    "FILE_NAME = \"1204_mnist_matsumoto_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9900\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list = os.listdir(PATH)\n",
    "list.sort(key=lambda fn: os.path.getmtime(PATH+fn) if not os.path.isdir(PATH+fn) else 0)\n",
    "print(list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fid_all_list(filePath, fid_dict={}):\n",
    "    fid = 'python3 -m pytorch_fid'\n",
    "\n",
    "    for i in os.listdir(filePath):\n",
    "        PATH_with_FILE = os.path.join(filePath, i)\n",
    "        FILE_NAME = i\n",
    "\n",
    "        file_list = os.listdir(PATH_with_FILE)\n",
    "        file_list.sort(key=lambda fn: os.path.getmtime(os.path.join(PATH_with_FILE,fn)) if not os.path.isdir(os.path.join(PATH_with_FILE,fn)) else 0)\n",
    "        max_value = int(file_list[-1]) + 1\n",
    "\n",
    "        # start FID calc\n",
    "        for i in range(0, max_value, 100):\n",
    "\n",
    "            real_path = ' ' + os.path.join(PATH_with_FILE, str(i)) + '/real_images'\n",
    "            fake_path = ' ' + os.path.join(PATH_with_FILE, str(i)) + '/fake_images'\n",
    "\n",
    "            command_line = fid + real_path + fake_path\n",
    "\n",
    "            args = shlex.split(command_line)\n",
    "\n",
    "            res = subprocess.run(args, shell=False, stdout=subprocess.PIPE, text=True)\n",
    "\n",
    "            fid_dict[i] = float(res.stdout[6:-1])\n",
    "\n",
    "    with open(FILE_NAME +'.log', \"w\") as tf:\n",
    "\n",
    "        print(PATH_with_FILE + '\\n', file=tf)\n",
    "\n",
    "        pprint.pprint(sorted(fid_dict.items(), key=lambda kv:kv[1]), stream=tf)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fid_one_list(filePath, fileNAME, fid_dict={}):\n",
    "    fid = 'python3 -m pytorch_fid'\n",
    "\n",
    "    PATH_with_FILE = os.path.join(filePath, fileNAME)\n",
    "\n",
    "    file_list = os.listdir(PATH_with_FILE)\n",
    "    file_list.sort(key=lambda fn: os.path.getmtime(os.path.join(PATH_with_FILE,fn)) if not os.path.isdir(os.path.join(PATH_with_FILE,fn)) else 0)\n",
    "    max_value = int(file_list[-1]) + 1\n",
    "\n",
    "    # start FID calc \n",
    "    for i in range(0, max_value, 100):\n",
    "\n",
    "        real_path = ' ' + os.path.join(PATH_with_FILE, str(i)) + '/real_images'\n",
    "        fake_path = ' ' + os.path.join(PATH_with_FILE, str(i)) + '/fake_images'\n",
    "\n",
    "        command_line = fid + real_path + fake_path\n",
    "\n",
    "        # split command line \n",
    "        args = shlex.split(command_line)\n",
    "\n",
    "        res = subprocess.run(args, shell=False, stdout=subprocess.PIPE, text=True)\n",
    "\n",
    "        fid_dict[i] = float(res.stdout[6:-1])\n",
    "\n",
    "    with open(fileNAME + '.log', 'w') as tf:\n",
    "\n",
    "        print(PATH_with_FILE + '\\n', file=tf)\n",
    "\n",
    "        pprint.pprint(sorted(fid_dict.items(), key=lambda kv:kv[1]), stream=tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/202 [00:00<?, ?it/s]/home/xchen/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████| 202/202 [00:11<00:00, 17.41it/s]\n",
      "100%|██████████| 202/202 [00:11<00:00, 17.47it/s]\n",
      "  0%|          | 0/202 [00:00<?, ?it/s]/home/xchen/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████| 202/202 [00:11<00:00, 17.59it/s]\n",
      "100%|██████████| 202/202 [00:11<00:00, 17.49it/s]\n",
      "  0%|          | 0/202 [00:00<?, ?it/s]/home/xchen/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████| 202/202 [00:11<00:00, 17.54it/s]\n",
      "100%|██████████| 202/202 [00:11<00:00, 17.48it/s]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pprint\n",
    "import shlex\n",
    "import subprocess\n",
    "\n",
    "filePath = \"/home/xchen/GANs/WGAN-div-PyTorch-/samples/\"\n",
    "fileNAME = \"1204_mnist_matsumoto_1\"\n",
    "\n",
    "# fid_all_list(filePath)\n",
    "fid_one_list(filePath, fileNAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/xchen/GANs/WGAN-div-PyTorch-/checkpoint/1216_cifar10_bs64_matsumoto_1/1500.pth.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-78209cba1c04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfixed_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mfake_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/xchen/GANs/WGAN-div-PyTorch-/checkpoint/1216_cifar10_bs64_matsumoto_1/1500.pth.tar'"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "import torch \n",
    "from models.wgan_div import Generator\n",
    "\n",
    "ckpt_path = \"/home/xchen/GANs/WGAN-div-PyTorch-/checkpoint/1216_cifar10_bs64_matsumoto_1/1500.pth.tar\"\n",
    "\n",
    "G = Generator().cuda()\n",
    "fixed_noise = torch.randn(10000, 100).cuda()\n",
    "\n",
    "torch.load(ckpt_path)\n",
    "\n",
    "fake_images = G(fixed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Generator                                --                        --\n",
      "├─Sequential: 1-1                        [64, 512, 4, 4]           --\n",
      "│    └─ConvTranspose2d: 2-1              [64, 512, 4, 4]           819,200\n",
      "│    └─BatchNorm2d: 2-2                  [64, 512, 4, 4]           1,024\n",
      "│    └─ReLU: 2-3                         [64, 512, 4, 4]           --\n",
      "├─Sequential: 1-2                        [64, 256, 8, 8]           --\n",
      "│    └─ConvTranspose2d: 2-4              [64, 256, 8, 8]           2,097,152\n",
      "│    └─BatchNorm2d: 2-5                  [64, 256, 8, 8]           512\n",
      "│    └─ReLU: 2-6                         [64, 256, 8, 8]           --\n",
      "├─Sequential: 1-3                        [64, 128, 16, 16]         --\n",
      "│    └─ConvTranspose2d: 2-7              [64, 128, 16, 16]         524,288\n",
      "│    └─BatchNorm2d: 2-8                  [64, 128, 16, 16]         256\n",
      "│    └─ReLU: 2-9                         [64, 128, 16, 16]         --\n",
      "├─Sequential: 1-4                        [64, 64, 32, 32]          --\n",
      "│    └─ConvTranspose2d: 2-10             [64, 64, 32, 32]          131,072\n",
      "│    └─BatchNorm2d: 2-11                 [64, 64, 32, 32]          128\n",
      "│    └─ReLU: 2-12                        [64, 64, 32, 32]          --\n",
      "├─Sequential: 1-5                        [64, 1, 64, 64]           --\n",
      "│    └─ConvTranspose2d: 2-13             [64, 1, 64, 64]           1,024\n",
      "│    └─Tanh: 2-14                        [64, 1, 64, 64]           --\n",
      "==========================================================================================\n",
      "Total params: 3,574,656\n",
      "Trainable params: 3,574,656\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 26.88\n",
      "==========================================================================================\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 127.93\n",
      "Params size (MB): 14.30\n",
      "Estimated Total Size (MB): 142.25\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Discriminator                            --                        --\n",
      "├─Sequential: 1-1                        [64, 64, 32, 32]          --\n",
      "│    └─Conv2d: 2-1                       [64, 64, 32, 32]          1,024\n",
      "│    └─LeakyReLU: 2-2                    [64, 64, 32, 32]          --\n",
      "├─Sequential: 1-2                        [64, 128, 16, 16]         --\n",
      "│    └─Conv2d: 2-3                       [64, 128, 16, 16]         131,072\n",
      "│    └─BatchNorm2d: 2-4                  [64, 128, 16, 16]         256\n",
      "│    └─LeakyReLU: 2-5                    [64, 128, 16, 16]         --\n",
      "├─Sequential: 1-3                        [64, 256, 8, 8]           --\n",
      "│    └─Conv2d: 2-6                       [64, 256, 8, 8]           524,544\n",
      "│    └─BatchNorm2d: 2-7                  [64, 256, 8, 8]           512\n",
      "│    └─LeakyReLU: 2-8                    [64, 256, 8, 8]           --\n",
      "├─Sequential: 1-4                        [64, 512, 4, 4]           --\n",
      "│    └─Conv2d: 2-9                       [64, 512, 4, 4]           2,097,664\n",
      "│    └─BatchNorm2d: 2-10                 [64, 512, 4, 4]           1,024\n",
      "│    └─LeakyReLU: 2-11                   [64, 512, 4, 4]           --\n",
      "├─Sequential: 1-5                        [64, 1, 1, 1]             --\n",
      "│    └─Conv2d: 2-12                      [64, 1, 1, 1]             8,192\n",
      "==========================================================================================\n",
      "Total params: 2,764,288\n",
      "Trainable params: 2,764,288\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 6.51\n",
      "==========================================================================================\n",
      "Input size (MB): 1.05\n",
      "Forward/backward pass size (MB): 92.28\n",
      "Params size (MB): 11.06\n",
      "Estimated Total Size (MB): 104.38\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "from models.wgan_div import Generator, Discriminator\n",
    "from torchinfo import summary\n",
    "import pprint\n",
    "\n",
    "G = Generator().cuda()\n",
    "D = Discriminator().cuda()\n",
    "\n",
    "# get model summary as string \n",
    "G_model_stats = summary(G, (64, 100), verbose=0)\n",
    "D_model_stats = summary(D, (64, 1, 64, 64), verbose=0)\n",
    "\n",
    "pprint.pprint(G_model_stats)\n",
    "pprint.pprint(D_model_stats)\n",
    "summary_str = str(G_model_stats), str(D_model_stats)\n",
    "with open('model_structure.log', 'w') as tf:\n",
    "    pprint.pprint(summary_str, stream=tf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74a93dc98ce132c7712e91561fec933a3a7586bb1208e240d679dc2b0a82ea21"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
